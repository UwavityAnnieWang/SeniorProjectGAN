{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a28564b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here are all of the imports that could be needed \n",
    "#we're just going to transition over to a new environment \n",
    "import tensorflow as tf \n",
    "#keras is now integrated with tensorflow \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "#import imageio\n",
    "#import cv2\n",
    "import pandas as pd \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers \n",
    "import time \n",
    "from IPython import display \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2243b779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2638 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#import dataset \n",
    "#the below method doesn't work because the function belongs to tensorflow nightly builds or whatever \n",
    "#update it's available on tensorflow 2.9.0 or something but conda only has access to 2.8.1 \n",
    "#dataset = tf.keras.preprocessing.image_dataset_from_directory('ImageDatasets')\n",
    "#Have to figure out how to import from subdirectories as well because of the organizational structure of \n",
    "#ImageDatasets\n",
    "#use flow_from_directory??? possibly\n",
    "\n",
    "#ok this found it now I have to somehow get it into the model \n",
    "#might want to refine how the data is loaded \n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory('ImageDatasets',  \n",
    "                                                              image_size=(431,431), batch_size=5)\n",
    "\n",
    "  \n",
    "#dataset = ImageDataGenerator().flow_from_directory(directory='ImageDatasets', batch_size=5, target_size = (431, 431)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#dataset = dataset.\n",
    "#normalization! \n",
    "\n",
    "#five to six batches should be good \n",
    "\n",
    "#how big should the batches be etc. \n",
    "#just have to change parameters in the flow_from_directory function I suppose \n",
    "\n",
    "#check the alice project to see how she processed her images etc. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fca3cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator code \n",
    "def make_discriminator():\n",
    "    model = tf.keras.Sequential(tf.keras.layers.experimental.preprocessing.Rescaling(1./255))\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "discriminator = make_discriminator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2703d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator code \n",
    "def make_generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model\n",
    "generator = make_generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2c2b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss and optimization \n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "#this is all standard, the things i have to change are probably how the data is loaded in itself\n",
    "#and like the training loop \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs\n",
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb8977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoints\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42eef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "#fixed indentation--for some reason it was weird \n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    \n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5ce3981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "            \n",
    " \n",
    "    # Produce images for the GIF as you go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "        \n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "    display.clear_output(wait=True)\n",
    "    #Generate after the final epoch \n",
    "    generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a50afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating and saving images \n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0]*127.5+127.5)\n",
    "        plt.axis('off')\n",
    "    plt.savefig('image_at_epoch{:04d}.png'.format(epoch))\n",
    "    plt.show()\n",
    "  #will have to change this\n",
    "#one image? two images? \n",
    "#time to edit this :/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5661456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the guy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9038fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic code to get started \n",
    "#annotate example code \n",
    "#another dead code graveyard, outdated, could use as reference \n",
    "\n",
    "'''from __future__ import print_function, division\n",
    "#imports the handwriting dataset \n",
    "from keras.datasets import mnist\n",
    "#functions for layers probably \n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "#more processing stuff (have to look up actual function)\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class GAN():\n",
    "    def __init__(self):\n",
    "        #what is this doing \n",
    "        # i have to look up all of the keras functions involved and annotate \n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Train the generator (to have the discriminator label samples as valid)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gan = GAN()\n",
    "    gan.train(epochs=30000, batch_size=32, sample_interval=200)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfe6fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ded code graveyard \n",
    "'''#below is old code that doesn't work :/ \n",
    "\tif r.status_code == 200: \n",
    "\t\tif i.contains('png'):\n",
    "\t\t\twith open(\"*?.png\", \"wb\") as f:\n",
    "\t\t\t\tr.raw.decode_content = True\n",
    "\t\t\t\tshutil.copyfileobj(r.raw, f)\n",
    "\t\telse:\n",
    "\t\t\twith open(\"*?.jpg\", \"wb\") as f:\n",
    "\t\t\t\tr.raw.decode_content = True\n",
    "\t\t\t\tshutil.copyfileobj(r.raw, f)\n",
    "\n",
    "\t\t\t#\t\t    shutil.copyfileobj(r.raw, f)\n",
    "\t\t\t\n",
    "\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t                    #200 status code = OK'''\n",
    "\t\t'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
